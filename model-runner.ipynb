{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a75f14-a139-463a-99b6-4841a2022148",
   "metadata": {},
   "source": [
    "### Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b0d4b-48a1-4fc6-a0c4-c6130f7c7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('secret_tokens.json') as f:\n",
    "    tokens_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0504e77d-67be-4b03-a054-83b2d1dc2518",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "### CodeLLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff65f1-59dd-4c5e-8598-08b3b5d5aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(clw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f241a8baeea1e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import codellama_wrapper as clw\n",
    "codellama_trial = clw.CodellamaEval(model_name = \"codellama/CodeLlama-7b-hf\", gpu_id=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e98d8-4eda-4303-8495-878db904c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "codellama_trial.generate()\n",
    "file_name = codellama_trial.model_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a09a0-4c8f-4336-8c62-da739f54e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "codellama_trial.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d8c98-2cde-4700-b1f9-dfaa64379f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have a json with the data, we can run just the eval and skip the generation\n",
    "import importlib\n",
    "importlib.reload(clw)\n",
    "clt = clw.CodellamaEval(model_name = None, method_dict_location = 'output_multi-humaneval_CodeLlama-7b-hf.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7b724-80e6-46a2-902c-d8736b99fa62",
   "metadata": {},
   "source": [
    "### Refact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1970a8a-4bd7-4f63-b5af-d0a355384105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've implemented new multi_evaluate routine that does everything in one click.\n",
    "# Unlike generic evaluate, it runs code generation several times and evaluates several iterations. In the end this yields pass@1 averaged over several runs\n",
    "# One generation + eval takes circa 15 minutes on one 4090 GPU\n",
    "import causallm_wrapper as clmw\n",
    "refact = clmw.CausalLMEval(gpu_id = 0)\n",
    "refact.multi_evaluate(iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516eec65-fa41-4687-9926-09264874942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For CausalLM wrapper, I've also added loading from checkpoint, which can be used as follows\n",
    "import causallm_wrapper as clmw\n",
    "refact2 = clmw.CausalLMEval(model_checkpoint = './checkpoint/stack_tuned.ckpt', gpu_id = 0)\n",
    "refact2.multi_evaluate(iterations = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68842ecd-c7b8-4933-937c-741de434bbb4",
   "metadata": {},
   "source": [
    "### Dataset fiddling (for dev purposes, you are unlikely to need that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fcc44-791a-41cd-a8e7-b5b222fbd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('output_multi-humaneval_Refact-1_6B-fim.json') as f:\n",
    "    results_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4f754-8dc6-4afc-a205-da90dadb5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open('output_multi-humaneval_Refact-1_6B-fim.jsonl_results.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        print(obj['task_id'])\n",
    "        print(obj['completion'])\n",
    "        print(obj['result'])\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5783dc-ac7c-429c-a763-8d45c33c97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(refact.raw_method_list):\n",
    "    print(i)\n",
    "    print(item)\n",
    "    print('\\n')\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3afb51-c289-4316-be19-89fad1863c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_multi-humaneval_Refact-1_6B-fim.jsonl_results.jsonl') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    line_dicts = [json.loads(line) for line in lines]\n",
    "df = pd.DataFrame(line_dicts)\n",
    "pretty_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a0093-ec3a-4084-b110-98ecedb504bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open(file_name) as reader:\n",
    "    for obj in reader:\n",
    "        print(obj['completion'])\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f149a4-8ce8-4da5-9734-f561ed544153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eac511-ce16-4ded-b3d0-14ff5ed0c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7575b3-17e3-4771-9f71-664d39dd74a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decf180-3fb3-49f4-867f-8377f06ec81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
